{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Week4_Exercise_Shakespeare_Answer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayajpayak/Tensorflow/blob/master/NLP_Week4_Exercise_Shakespeare_Answer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRnDnCW-Z7qv",
        "outputId": "59554b3d-0900-4276-dbd7-e1157c55a446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-23 01:18:14--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 2404:6800:4003:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2019-09-23 01:18:14 (168 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL",
        "colab_type": "code",
        "outputId": "f7f6ba91-0ada-451d-b40e-9e1d43e14bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0923 01:18:20.432975 139724914681728 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/initializers.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0923 01:18:20.456285 139724914681728 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0923 01:18:20.463016 139724914681728 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0923 01:18:20.465121 139724914681728 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0923 01:18:20.466371 139724914681728 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:97: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 300)           301200    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 10, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1605)              162105    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 6,101,671\n",
            "Trainable params: 6,101,671\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIg2f1HBxqof",
        "colab_type": "code",
        "outputId": "560d1964-dc31-40de-ec50-ad8c55eff0ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " history = model.fit(predictors, label, epochs=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0923 01:18:25.164336 139724914681728 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 6.9030 - acc: 0.0208\n",
            "Epoch 2/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.4984 - acc: 0.0216\n",
            "Epoch 3/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.3739 - acc: 0.0275\n",
            "Epoch 4/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.2520 - acc: 0.0326\n",
            "Epoch 5/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.1661 - acc: 0.0362\n",
            "Epoch 6/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.0898 - acc: 0.0411\n",
            "Epoch 7/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 6.0092 - acc: 0.0409\n",
            "Epoch 8/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.9155 - acc: 0.0475\n",
            "Epoch 9/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 5.8121 - acc: 0.0526\n",
            "Epoch 10/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.7049 - acc: 0.0600\n",
            "Epoch 11/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.6012 - acc: 0.0641\n",
            "Epoch 12/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.5013 - acc: 0.0701\n",
            "Epoch 13/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.3966 - acc: 0.0786\n",
            "Epoch 14/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.2897 - acc: 0.0836\n",
            "Epoch 15/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.1841 - acc: 0.0915\n",
            "Epoch 16/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 5.0785 - acc: 0.0982\n",
            "Epoch 17/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.9767 - acc: 0.1059\n",
            "Epoch 18/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.8754 - acc: 0.1140\n",
            "Epoch 19/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.7730 - acc: 0.1176\n",
            "Epoch 20/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.6748 - acc: 0.1301\n",
            "Epoch 21/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.5764 - acc: 0.1388\n",
            "Epoch 22/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.4773 - acc: 0.1463\n",
            "Epoch 23/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 4.3732 - acc: 0.1579\n",
            "Epoch 24/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.2732 - acc: 0.1682\n",
            "Epoch 25/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.1697 - acc: 0.1846\n",
            "Epoch 26/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 4.0616 - acc: 0.1937\n",
            "Epoch 27/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.9668 - acc: 0.2114\n",
            "Epoch 28/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.8678 - acc: 0.2242\n",
            "Epoch 29/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.7690 - acc: 0.2440\n",
            "Epoch 30/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.6808 - acc: 0.2630\n",
            "Epoch 31/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.5800 - acc: 0.2842\n",
            "Epoch 32/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 3.5021 - acc: 0.3024\n",
            "Epoch 33/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.4111 - acc: 0.3232\n",
            "Epoch 34/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.3233 - acc: 0.3372\n",
            "Epoch 35/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.2483 - acc: 0.3557\n",
            "Epoch 36/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.1706 - acc: 0.3708\n",
            "Epoch 37/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.0913 - acc: 0.3895\n",
            "Epoch 38/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 3.0076 - acc: 0.4098\n",
            "Epoch 39/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.9422 - acc: 0.4182\n",
            "Epoch 40/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.8820 - acc: 0.4380\n",
            "Epoch 41/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.8123 - acc: 0.4579\n",
            "Epoch 42/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.7524 - acc: 0.4652\n",
            "Epoch 43/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.6771 - acc: 0.4841\n",
            "Epoch 44/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.6288 - acc: 0.4944\n",
            "Epoch 45/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.5724 - acc: 0.5075\n",
            "Epoch 46/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.5137 - acc: 0.5178\n",
            "Epoch 47/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.4572 - acc: 0.5362\n",
            "Epoch 48/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.4059 - acc: 0.5437\n",
            "Epoch 49/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.3520 - acc: 0.5573\n",
            "Epoch 50/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.3147 - acc: 0.5654\n",
            "Epoch 51/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.2638 - acc: 0.5770\n",
            "Epoch 52/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.2140 - acc: 0.5857\n",
            "Epoch 53/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.1712 - acc: 0.5950\n",
            "Epoch 54/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.1265 - acc: 0.6120\n",
            "Epoch 55/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.0884 - acc: 0.6162\n",
            "Epoch 56/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.0438 - acc: 0.6259\n",
            "Epoch 57/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 2.0122 - acc: 0.6356\n",
            "Epoch 58/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.9755 - acc: 0.6381\n",
            "Epoch 59/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.9338 - acc: 0.6510\n",
            "Epoch 60/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.9169 - acc: 0.6517\n",
            "Epoch 61/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.8779 - acc: 0.6577\n",
            "Epoch 62/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.8436 - acc: 0.6686\n",
            "Epoch 63/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.8092 - acc: 0.6734\n",
            "Epoch 64/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.7808 - acc: 0.6793\n",
            "Epoch 65/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.7566 - acc: 0.6871\n",
            "Epoch 66/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.7201 - acc: 0.6909\n",
            "Epoch 67/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.6863 - acc: 0.7017\n",
            "Epoch 68/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.6686 - acc: 0.7020\n",
            "Epoch 69/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.6518 - acc: 0.7063\n",
            "Epoch 70/100\n",
            "15462/15462 [==============================] - 25s 2ms/sample - loss: 1.6203 - acc: 0.7117\n",
            "Epoch 71/100\n",
            "15462/15462 [==============================] - 24s 2ms/sample - loss: 1.5980 - acc: 0.7196\n",
            "Epoch 72/100\n",
            "  320/15462 [..............................] - ETA: 23s - loss: 1.3199 - acc: 0.7781"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXTEO3GJ282",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}